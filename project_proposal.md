# VoiceSphere: Empowering Conversations with LLamA-13B

## Team Members:
- Akshay Joshi
- Akash Sapkal
- Dhruv Shah
- Harshil Rathod
- Mariya Mansuri
- Neha Sharma

## Introduction
In the realm of digital innovation, the concept of voice assistants stands as a beacon of human-computer interaction, bringing forth a blend of convenience and advanced technological interplay. The project at hand, VoiceSphere, is poised to leap forward in this domain by harnessing the power of multimodal Large Language Models (LLM), specifically focusing on "Llava" and "Whisper" technologies. VoiceSphere aspires to transcend the current limitations observed in existing voice assistants, which often revert to providing web links for complex queries rather than offering precise, actionable information. Unlike these conventional systems, VoiceSphere aims to deliver a more integrated, intelligent, and user-centric experience, reminiscent of the nuanced interactions facilitated by platforms like ChatGPT.

### Project Proposal: AI Voice Assistant Using Multimodal LLM

#### Objective
The primary goal is to develop an advanced AI voice assistant application named VoiceSphere, which utilizes the capabilities of multimodal Large Language Models, such as "Llava" for generating human-like responses and "Whisper" for accurate speech recognition. This application seeks to offer a seamless, versatile, and user-friendly assistant capable of handling a broad spectrum of tasks through voice commands, effectively bridging the gap between human intent and digital execution.

#### Background
The proliferation of voice assistants has marked a significant shift in how users interact with technology, favoring natural and intuitive modes of communication. The integration of advanced multimodal LLMs like "Llava" and "Whisper" into VoiceSphere presents a promising avenue to elevate these interactions, offering users an experience that closely mirrors genuine human conversation.

#### Project Description
VoiceSphere will be developed as a web application leveraging "Llava" for its exceptional processing and understanding of user inputs, alongside "Whisper" for its superior speech-to-text conversion capabilities. The application will adeptly manage tasks ranging from setting reminders to controlling smart home devices, all operable through simple voice commands.

#### Technical Approach
- **Speech Recognition:** Incorporate "Whisper" for its robust speech-to-text conversion.
- **Natural Language Processing:** Utilize "Llava" to comprehend and interpret the context and meaning behind user commands, ensuring accurate and relevant responses.
- **User Interface Design:** Craft a user-centric interface that facilitates voice interactions, complemented by visual feedback for enhanced usability.
- **Integration:** Enable seamless integration with diverse APIs and services to support a wide array of tasks, including but not limited to calendar management and weather updates.

#### Milestones
1. **Research and Planning:** Deep dive into the capabilities of "Llava" and "Whisper", precisely defining the assistant's functional scope.
2. **Development Phase 1:** Establish core functionalities, focusing on speech recognition and fundamental command processing.
3. **Development Phase 2:** Broaden the assistant's capabilities by incorporating additional tasks and external service integrations.
4. **Testing and Refinement:** Execute comprehensive testing to ensure the assistant's reliability and gather user feedback for iterative improvement.

#### Project Stakeholders

- **Project Manager**: Manages project timelines, budgets, and overall progress.
- **End-Users**: Consumers or businesses who will use VoiceSphere, providing crucial feedback.
- **Investors or Sponsors**: Provide funding and are interested in the financial success of the project.
- **Technology Partners**: Suppliers of technologies like "Llava" and "Whisper" LLMs.
- **Data Scientists and AI Experts**: Specialists advising on the technical aspects of AI and machine learning.
- **External Developers**: If applicable, developers interested in building applications on top of VoiceSphere's platform.

#### Budget and Resources
The budget will cover expenses related to software development tools, cloud services for application hosting and data processing, and any requisite licenses for "Llava" and "Whisper". The project will mobilize a skilled team comprising developers, designers, and testers dedicated to bringing VoiceSphere to fruition.

#### Expected Outcomes
Upon completion, VoiceSphere is anticipated to redefine the landscape of AI voice assistants, offering enhanced user interaction through sophisticated natural language processing and speech recognition. This breakthrough will not only elevate the standards for voice assistant capabilities but also pave the way for further technological advancements in this field.

## References

1. Grozdić, Đ. T., & Jovičić, S. T. (2017). Whispered speech recognition using deep denoising autoencoder and inverse filtering. _IEEE/ACM Transactions on Audio, Speech, and Language Processing_.
2. Sharma, Y., Sharan, V., & Arora, J. (2021, December). The Study Of Voice Bots And Its Impact On Human Welfare. In _Proceedings of the International Conference on Advances in Management Practices_.
3. Liu, S., Cheng, H., Liu, H., Zhang, H., Li, F., Ren, T., ... & Li, C. (2023). Llava-plus: Learning to use tools for creating multimodal agents.
4. Wang, S., Yang, C. H. H., Wu, J., & Zhang, C. (2023). Can whisper perform speech-based in-context learning.